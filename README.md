# Решение для повышения фотореализма

## Описание решения

При обучении на вход модели-генератору подаются стилизованные, модифицированные изображения реального домена, из которых модель должна восстановить реалистично выглядящий кадр. Ground Truth здесь - соответсвующие оригинальные не модифицированные изображения реального домена.

При предсказании на вход модели-генератору подаются стилизованные и модифицированные виртуальные изображения, и так как модель обучалась на данных реального домена, ожидается, что результатом генерации будут фотореалистичные изображения.

Модель работает не на отдельных кадрах, а на последовательностях кадров из видео для обеспечения временной консистентности результата, поэтому в данных для каждого видеофрагмента не должно быть пропусков кадров.

## Подготовка данных

Требуются последовательности данных (кадры видео).
Необходимо подготовить две папки: с данными для обучения (`<train_dir> `) и данными для валидации (`<val_dir>`).
Папка `<train_dir>` содержит подпапку `real` с реальными данными, папка `<val_dir>` содержит две подпапки: `real` и `virtual` - с реальными и виртуальными данными соответственно. Каждая из подпапок имеет одинаковую структуру:
```
<dataset_dir>                       <real/virtual dir>
    ├- <train_dir>                      ├- <video1_name>
    │   └- real                         │   ├- frames
    └- <val_dir>                        │   ├- <modality1_name>
        ├- real                         │   ├- <modality2_name>
        └- virtual                      │   ...
                                        │   └- <modalityN_name>
                                        ├- <video2_name>
                                        │   ├- frames
                                        │   ├- <modality1_name>
                                        │   ...
                                        │   └- <modalityN_name>
                                       ...  ...
                                        └- <videoN_name>
                                            ├- frames
                                            ├- <modality1_name>
                                            ...
                                            └- <modalityN_name>
```
- `frames` - это кадры видео (должны быть без пропусков, имена файлов позволяют отсортировать их по порядку)

- `<modalityX_name>` - это папка с обработанными кадрами видео (имена должны быть теми же): это могут быть сегментационные маски, размытые изображения и т.д.

## Подготовка конфигурационного файла для обучения
Для каждой сессии (запуска) обучения создаётся папка `<run_dir>`, в которую помещается конфигурационный файл `<cfg>.yaml`.

В данном репозитории есть примеры конфиг-файлов: experiments_multimodal

Подробное описание конфигурационного файла [здесь](config_guide.md).

## Запуск обучения
Создав папку для текущего запуска обучения `<run_dir>` и в ней - конфигурационный файл `<cfg>.yaml`, обучение запускается следующей командой (терминал запущен из корня проекта):
```
CUDA_VISIBLE_DEVICES=<1> python codes/main.py --exp_dir <2> --mode train --model TecoGAN --opt <3> --gpu_id 0
```
- `<1>`: номер видеокарты, на которой запускается обучение
- `<2>`: папка для текущей сессии обучения `<run_dir>`
- `<3>`: имя конфиг-файла `<cfg>.yaml`

## Выполнение вывода (предсказаний)
Вывод выполняется по валидационной выборке датасета (папка `<val_dir>`):
```
CUDA_VISIBLE_DEVICES=<1> python codes/main.py --exp_dir <2> --mode test --model TecoGAN --opt <3> --gpu_id 0
```
- `<1>`: номер видеокарты, на которой запускается обучение
- `<2>`: папка с текущей сессии обучения `<run_dir>`
- `<3>`: имя конфиг-файла `<cfg>.yaml`. 
  Важно, чтобы в конфиг-файле путь к желаемому файлу весов для вывода был указан в поле `model -> generator -> load_path`